{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Faron, cpmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from datetime import datetime\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "This kernel implements the O(n²) F1-Score expectation maximization algorithm presented in\n",
    "\"Ye, N., Chai, K., Lee, W., and Chieu, H.  Optimizing F-measures: A Tale of Two Approaches. In ICML, 2012.\"\n",
    "\n",
    "It solves argmax_(0 <= k <= n,[[None]]) E[F1(P,k,[[None]])]\n",
    "with [[None]] being the indicator for predicting label \"None\"\n",
    "given posteriors P = [p_1, p_2, ... , p_n], where p_1 > p_2 > ... > p_n\n",
    "under label independence assumption by means of dynamic programming in O(n²).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_plot(P, filename='expected_f1.png'):\n",
    "    E_F1 = pd.DataFrame(F1Optimizer.get_expectations(P).T, columns=[\"/w None\", \"/wo None\"])\n",
    "    best_k, _, max_f1 = F1Optimizer.maximize_expectation(P)\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    E_F1.plot()\n",
    "    plt.title('Expected F1-Score for \\n {}'.format(\"P = [{}]\".format(\",\".join(map(str, P)))), fontsize=12)\n",
    "    plt.xlabel('k')\n",
    "    plt.xticks(np.arange(0, len(P) + 1, 1.0))\n",
    "    plt.ylabel('E[F1(P,k)]')\n",
    "    plt.plot([best_k], [max_f1], 'o', color='#000000', markersize=4)\n",
    "    plt.annotate('max E[F1(P,k)] = E[F1(P,{})] = {:.5f}'.format(best_k, max_f1), xy=(best_k, max_f1),\n",
    "                 xytext=(best_k, max_f1 * 0.8), arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=7),\n",
    "                 horizontalalignment='center', verticalalignment='top')\n",
    "    plt.gcf().savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeit(P):\n",
    "    s = datetime.now()\n",
    "    F1Optimizer.maximize_expectation(P)\n",
    "    e = datetime.now()\n",
    "    return (e-s).microseconds / 1E6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark(n=100, filename='runtimes.png'):\n",
    "    results = pd.DataFrame(index=np.arange(1,n+1))\n",
    "    results['runtimes'] = 0\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        runtimes = []\n",
    "        for j in range(5):\n",
    "            runtimes.append(timeit(np.sort(np.random.rand(i))[::-1]))\n",
    "        results.iloc[i-1] = np.mean(runtimes)\n",
    "\n",
    "    x = results.index\n",
    "    y = results.runtimes\n",
    "    results['quadratic fit'] = np.poly1d(np.polyfit(x, y, deg=2))(x)\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    results.plot()\n",
    "    plt.title('Expectation Maximization Runtimes', fontsize=12)\n",
    "    plt.xlabel('n = |P|')\n",
    "    plt.ylabel('time in seconds')\n",
    "    plt.gcf().savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F1Optimizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    @jit\n",
    "    def get_expectations(P, pNone=None):\n",
    "        expectations = []\n",
    "        P = np.sort(P)[::-1]\n",
    "\n",
    "        n = np.array(P).shape[0]\n",
    "        DP_C = np.zeros((n + 2, n + 1))\n",
    "        if pNone is None:\n",
    "            pNone = (1.0 - P).prod()\n",
    "\n",
    "        DP_C[0][0] = 1.0\n",
    "        for j in range(1, n):\n",
    "            DP_C[0][j] = (1.0 - P[j - 1]) * DP_C[0, j - 1]\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(1, n + 1):\n",
    "            DP_C[i, i] = DP_C[i - 1, i - 1] * P[i - 1]\n",
    "            for j in range(i + 1, n + 1):\n",
    "                DP_C[i, j] = P[j - 1] * DP_C[i - 1, j - 1] + (1.0 - P[j - 1]) * DP_C[i, j - 1]\n",
    "        \n",
    "        DP_S = np.zeros((2 * n + 1,))\n",
    "        DP_SNone = np.zeros((2 * n + 1,))\n",
    "        for i in range(1, 2 * n + 1):\n",
    "            DP_S[i] = 1. / (1. * i)\n",
    "            DP_SNone[i] = 1. / (1. * i + 1)\n",
    "        \n",
    "        \n",
    "        for k in range(n + 1)[::-1]:\n",
    "            f1 = 0\n",
    "            f1None = 0\n",
    "            for k1 in range(n + 1):\n",
    "                f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n",
    "                f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]\n",
    "            for i in range(1, 2 * k - 1):\n",
    "                DP_S[i] = (1 - P[k - 1]) * DP_S[i] + P[k - 1] * DP_S[i + 1]\n",
    "                DP_SNone[i] = (1 - P[k - 1]) * DP_SNone[i] + P[k - 1] * DP_SNone[i + 1]\n",
    "\n",
    "            expectations.append([f1None + 2 * pNone / (2 + k), f1])\n",
    "\n",
    "        return np.array(expectations[::-1]).T\n",
    "\n",
    "    @staticmethod\n",
    "    @jit\n",
    "    def maximize_expectation(P, pNone=None):\n",
    "        expectations = F1Optimizer.get_expectations(P, pNone)\n",
    "\n",
    "        ix_max = np.unravel_index(expectations.argmax(), expectations.shape)\n",
    "        max_f1 = expectations[ix_max]\n",
    "\n",
    "        predNone = True if ix_max[0] == 0 else False\n",
    "        best_k = ix_max[1]\n",
    "\n",
    "        return best_k, predNone, max_f1\n",
    "\n",
    "    @staticmethod\n",
    "    def _F1(tp, fp, fn):\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    @staticmethod\n",
    "    def _Fbeta(tp, fp, fn, beta=1.0):\n",
    "        beta_squared = beta ** 2\n",
    "        return (1.0 + beta_squared) * tp / ((1.0 + beta_squared) * tp + fp + beta_squared * fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_best_prediction(P, pNone=None):\n",
    "    print(\"Maximize F1-Expectation\")\n",
    "    print(\"=\" * 23)\n",
    "    P = np.sort(P)[::-1]\n",
    "    n = P.shape[0]\n",
    "    L = ['L{}'.format(i + 1) for i in range(n)]\n",
    "\n",
    "    if pNone is None:\n",
    "        print(\"Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)\")\n",
    "        pNone = (1.0 - P).prod()\n",
    "\n",
    "    PL = ['p({}|x)={}'.format(l, p) for l, p in zip(L, P)]\n",
    "    print(\"Posteriors: {} (n={})\".format(PL, n))\n",
    "    print(\"p(None|x)={}\".format(pNone))\n",
    "\n",
    "    opt = F1Optimizer.maximize_expectation(P, pNone)\n",
    "    best_prediction = ['None'] if opt[1] else []\n",
    "    best_prediction += (L[:opt[0]])\n",
    "    f1_max = opt[2]\n",
    "\n",
    "    print(\"Prediction {} yields best E[F1] of {}\\n\".format(best_prediction, f1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximize F1-Expectation\n",
      "=======================\n",
      "Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)\n",
      "Posteriors: ['p(L1|x)=0.21078201', 'p(L2|x)=0.15028484', 'p(L3|x)=0.14119421', 'p(L4|x)=0.14067706', 'p(L5|x)=0.12568891', 'p(L6|x)=0.12319331', 'p(L7|x)=0.07946364', 'p(L8|x)=0.07354934', 'p(L9|x)=0.05557247', 'p(L10|x)=0.05122091', 'p(L11|x)=0.04982959', 'p(L12|x)=0.04392242', 'p(L13|x)=0.04345719'] (n=13)\n",
      "p(None|x)=0.251934466899\n",
      "Prediction ['None', 'L1'] yields best E[F1] of 0.276997323776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = [0.21078201, 0.15028484, 0.14119421, 0.14067706, 0.12568891, 0.12319331, 0.07946364, 0.07354934,\n",
    "     0.05557247, 0.05122091, 0.04982959, 0.04392242, 0.04345719]\n",
    "#k= [0.5, 0.4, 0.3, 0.35, 0.33, 0.31, 0.29, 0.27, 0.25, 0.20, 0.15, 0.10]\n",
    "\n",
    "print_best_prediction(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximize F1-Expectation\n",
      "=======================\n",
      "Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)\n",
      "Posteriors: ['p(L1|x)=0.3', 'p(L2|x)=0.2'] (n=2)\n",
      "p(None|x)=0.56\n",
      "Prediction ['None', 'L1'] yields best E[F1] of 0.563333333333\n",
      "\n",
      "Maximize F1-Expectation\n",
      "=======================\n",
      "Posteriors: ['p(L1|x)=0.3', 'p(L2|x)=0.2'] (n=2)\n",
      "p(None|x)=0.57\n",
      "Prediction ['None'] yields best E[F1] of 0.57\n",
      "\n",
      "Maximize F1-Expectation\n",
      "=======================\n",
      "Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)\n",
      "Posteriors: ['p(L1|x)=0.9', 'p(L2|x)=0.6'] (n=2)\n",
      "p(None|x)=0.04\n",
      "Prediction ['L1', 'L2'] yields best E[F1] of 0.82\n",
      "\n",
      "Maximize F1-Expectation\n",
      "=======================\n",
      "Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)\n",
      "Posteriors: ['p(L1|x)=0.5', 'p(L2|x)=0.4', 'p(L3|x)=0.35', 'p(L4|x)=0.33', 'p(L5|x)=0.31', 'p(L6|x)=0.3', 'p(L7|x)=0.29', 'p(L8|x)=0.27', 'p(L9|x)=0.25', 'p(L10|x)=0.2', 'p(L11|x)=0.15', 'p(L12|x)=0.1'] (n=12)\n",
      "p(None|x)=0.0150124107738\n",
      "Prediction ['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9'] yields best E[F1] of 0.463650930249\n",
      "\n",
      "Maximize F1-Expectation\n",
      "=======================\n",
      "Posteriors: ['p(L1|x)=0.5', 'p(L2|x)=0.4', 'p(L3|x)=0.35', 'p(L4|x)=0.33', 'p(L5|x)=0.31', 'p(L6|x)=0.3', 'p(L7|x)=0.29', 'p(L8|x)=0.27', 'p(L9|x)=0.25', 'p(L10|x)=0.2', 'p(L11|x)=0.15', 'p(L12|x)=0.1'] (n=12)\n",
      "p(None|x)=0.2\n",
      "Prediction ['None', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9'] yields best E[F1] of 0.466401481037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print_best_prediction([0.3, 0.2])\n",
    "    print_best_prediction([0.3, 0.2], 0.57)\n",
    "    print_best_prediction([0.9, 0.6])\n",
    "    print_best_prediction([0.5, 0.4, 0.3, 0.35, 0.33, 0.31, 0.29, 0.27, 0.25, 0.20, 0.15, 0.10])\n",
    "    print_best_prediction([0.5, 0.4, 0.3, 0.35, 0.33, 0.31, 0.29, 0.27, 0.25, 0.20, 0.15, 0.10], 0.2)\n",
    "\n",
    "    save_plot([0.45, 0.35, 0.31, 0.29, 0.27, 0.25, 0.22, 0.20, 0.17, 0.15, 0.10, 0.05, 0.02])\n",
    "    benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
